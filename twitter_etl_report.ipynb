{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e754a7-c99e-489a-8190-7a7801e98196",
   "metadata": {},
   "source": [
    "<h1 align='center'>Twitter API and NLP</h1>\n",
    "\n",
    "<h2>Importación de las Librerías</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a655636-d316-4126-b4d6-ae3fd81a28ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries successfully loaded...\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import copy\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tweepy\n",
    "\n",
    "from utils import functions, querys\n",
    "print('All libraries successfully loaded...')\n",
    "\n",
    "import urllib3 # Just for the runner and debugger\n",
    "import importlib # Delete for production and use importlib.reload(<module>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d42c0-78a6-4daa-b8e0-d3b8487ae35d",
   "metadata": {},
   "source": [
    "<h2>Debugging Toolkit</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50131365-54df-4eda-a489-04376014c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si falló el último paso, abra Anaconda Prompt e ingrese los siguientes comandos:\n",
      "\n",
      "1) conda activate Twitter-API\n",
      "2) pip install -r c:\\Users\\nicol\\Proyectos\\GitHub\\Consultorías\\Twitter\\trade_union_tweets\\requirements.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Debugging message for first loadings\n",
    "environ = sys.prefix[sys.prefix.rindex('\\\\')+1:]\n",
    "print('Si falló el último paso, abra Anaconda Prompt e ingrese los siguientes comandos:\\n\\n' +\n",
    "      f'1) conda activate {environ}\\n' + f'2) pip install -r {os.getcwd()}\\\\requirements.txt')\n",
    "\n",
    "# Typing library is not built-in\n",
    "from typing import Optional\n",
    "\n",
    "# And this debugging controller requires it to work\n",
    "def display_control(df: pd.DataFrame, value: Optional[int] = None,\n",
    "                    axis: Optional[int] = 0):\n",
    "    \n",
    "    dict_axis = {0: \"rows\", 1: \"columns\"}\n",
    "    \n",
    "    if value:\n",
    "        pd.set_option(f\"max_{dict_axis[axis]}\", value)\n",
    "        \n",
    "    display(df)\n",
    "    pd.reset_option(f\"max_{dict_axis[axis]}\")\n",
    "    \n",
    "# Timer start\n",
    "start = time.time() \n",
    "    \n",
    "# Pandas configuration for tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed9f4a-10c9-493b-9e11-9b5bfba6f3ba",
   "metadata": {},
   "source": [
    "<h2>Configuraciones Generales</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5117273c-a454-496c-b596-9751600c929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos de 3 cuentas, desde el 2017-01-01 hasta hoy...\n"
     ]
    }
   ],
   "source": [
    "# We store our starting day and start the time\n",
    "tz = pytz.timezone('America/Santiago')\n",
    "santiago_now = datetime.now(tz)\n",
    "\n",
    "# We define a day range to store\n",
    "stored_since = santiago_now - timedelta(days=7)\n",
    "date_stored = stored_since.strftime('%Y%m%d')\n",
    "\n",
    "# Creating IDs for storage and starting our time counter \n",
    "date_id = santiago_now.strftime(\"%Y%m%d\")\n",
    "time_id = santiago_now.strftime(\"%H%M\")\n",
    "\n",
    "# dict_accounts = {\"cutchile\": 289376883, \"confed_bancaria\": 607178284,\n",
    "#                  \"confusamchile\": 203352616, \"fenpruss\": 75044282,\n",
    "#                  \"cotraporchi\": 3402211569, \"confecobre\": 262411747}\n",
    "\n",
    "dict_accounts = {\"fenpruss\": 75044282, \"fenassap\": 750476199810457601,\n",
    "                 \"confusamchile\": 203352616} #, \"fenpruss\": 75044282,\n",
    "#                  \"cotraporchi\": 3402211569, \"confecobre\": 262411747}\n",
    "\n",
    "# Limit date definition\n",
    "since = \"2017-01-01\"\n",
    "dttm_since = f\"{since}T00:00:00Z\"\n",
    "\n",
    "# Pandas configuration\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"Descargando datos de {len(dict_accounts.keys())} cuentas, desde el \"\n",
    "      f\"{since} hasta hoy...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fad1e7-4f14-425d-8f39-28602af4ba56",
   "metadata": {},
   "source": [
    "<h2>Obtención de las Credenciales</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b26bf7a-248f-49db-bbc3-b8c62a8a8237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credenciales cargadas: twitter_key, twitter_secret, twitter_token, token_access, token_secret...\n"
     ]
    }
   ],
   "source": [
    "# We obtain the script's path independent of our OS\n",
    "path_children = ['credentials', 'credentials.txt']\n",
    "credentials_path = functions.script_path(path_children)\n",
    "\n",
    "# We instantiate and fill our dictionary\n",
    "with open(credentials_path) as file:\n",
    "    lines = file.readlines()\n",
    "    credentials = dict()\n",
    "    \n",
    "    for line in lines:\n",
    "        credentials.update(ast.literal_eval(line))\n",
    "        \n",
    "print(f\"Credenciales cargadas: {', '.join([*credentials.keys()])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792c50d-d027-494a-86d9-90fe35ce96a0",
   "metadata": {},
   "source": [
    "<h2>Levantamiento de los Clientes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde9f3a8-aaa4-4299-a2f1-e9114647ed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables ambientales levantadas, preparando funciones clave...\n"
     ]
    }
   ],
   "source": [
    "# We obtain and set our token for Twitter\n",
    "os.environ[\"BEARER_TOKEN\"] = credentials['twitter_token']\n",
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "print(\"Variables ambientales levantadas, preparando funciones clave...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300020b-24a4-4999-8fb3-e4a72581604f",
   "metadata": {},
   "source": [
    "<h2>Definición de Funciones Clave</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065b6379-bbff-44e0-b605-eb0016782c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones definidas y listas para usarse. Extrayendo tweets...\n"
     ]
    }
   ],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2FullArchiveSearchPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.request(\"GET\", search_url, auth=bearer_oauth, params=params)\n",
    "#     print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "print(\"Funciones definidas y listas para usarse. Extrayendo tweets...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84677d-5214-4b02-8bba-49daf094db0e",
   "metadata": {},
   "source": [
    "<h2>Loop de Extracción de Datos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2328f286-a8d4-479d-8500-c421aec316d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se extrajeron 480 tweets de FENPRUSS, donde la última publicación fue el día 2021-03-12...\n",
      "Se extrajeron 494 tweets de FENPRUSS, donde la última publicación fue el día 2020-05-28...\n",
      "Se extrajeron 496 tweets de FENPRUSS, donde la última publicación fue el día 2019-03-30...\n",
      "Se extrajeron 150 tweets de FENPRUSS, donde la última publicación fue el día 2017-01-07...\n",
      "Se extrajeron 382 tweets de FENASSAP, donde la última publicación fue el día 2017-03-28...\n",
      "Se extrajeron 483 tweets de CONFUSAMCHILE, donde la última publicación fue el día 2021-03-26...\n",
      "Se extrajeron 484 tweets de CONFUSAMCHILE, donde la última publicación fue el día 2020-10-14...\n",
      "Se extrajeron 496 tweets de CONFUSAMCHILE, donde la última publicación fue el día 2020-05-08...\n",
      "Se extrajeron 500 tweets de CONFUSAMCHILE, donde la última publicación fue el día 2019-10-22...\n",
      "Se extrajeron 498 tweets de CONFUSAMCHILE, donde la última publicación fue el día 2017-03-26...\n",
      "Se extrajeron 29 tweets de CONFUSAMCHILE, donde la última publicación fue el día 2017-01-16...\n",
      "Información descargada exitosamente...\n"
     ]
    }
   ],
   "source": [
    "# Preparing our complete information dictionary\n",
    "tweets_by_account = {account: [] for account in dict_accounts.keys()}\n",
    "\n",
    "for account, account_id in dict_accounts.items():\n",
    "    while True:\n",
    "        search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "        query_params = {'query': f\"to:{account_id} -is:retweet\",\n",
    "                        'tweet.fields': 'created_at,public_metrics,entities',\n",
    "                        'start_time': dttm_since,\n",
    "                        \"max_results\": 500}\n",
    "\n",
    "        if len(tweets_by_account[account]) > 0:\n",
    "            meta = json_response['meta']\n",
    "\n",
    "            if 'next_token' in meta:\n",
    "                query_params['next_token'] = meta['next_token']\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        json_response = connect_to_endpoint(search_url, query_params)\n",
    "        data, meta = [json_response[key] for key in json_response.keys()]\n",
    "        \n",
    "        tweets_by_account[account].append({'meta': meta, 'data': data})\n",
    "\n",
    "        print(f\"Se extrajeron {len(json_response['data'])} tweets de \"\n",
    "              f\"{account.upper()}, donde la última publicación fue el día \"\n",
    "              f\"{parser.parse(json_response['data'][-1]['created_at']).date()}...\")\n",
    "\n",
    "print('Información descargada exitosamente...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722d939-a9ab-4c9e-ae02-4fad2cf6dabd",
   "metadata": {},
   "source": [
    "<h2>Generación del Dataframe y Descarga como Excel</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b613e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '@ConfusamChile https://t.co/iP3sD1f5Ok',\n",
       " 'created_at': '2017-01-16T23:09:41.000Z',\n",
       " 'public_metrics': {'retweet_count': 2,\n",
       "  'reply_count': 1,\n",
       "  'like_count': 0,\n",
       "  'quote_count': 0},\n",
       " 'entities': {'mentions': [{'start': 0,\n",
       "    'end': 14,\n",
       "    'username': 'ConfusamChile',\n",
       "    'id': '203352616'}],\n",
       "  'urls': [{'start': 15,\n",
       "    'end': 38,\n",
       "    'url': 'https://t.co/iP3sD1f5Ok',\n",
       "    'expanded_url': 'https://twitter.com/mileschile/status/821019533443993600',\n",
       "    'display_url': 'twitter.com/mileschile/sta…'}]},\n",
       " 'id': '821132343951978497',\n",
       " 'url': 'https://t.co/iP3sD1f5Ok'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41085784-ac52-47b7-b3ca-401cc301155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': {'urls': [{'start': 149, 'end': 172, 'url': 'https://t.co/nV54PaB61E', 'expanded_url': 'https://twitter.com/ingralej/status/1532075533231476736/photo/1', 'display_url': 'pic.twitter.com/nV54PaB61E', 'media_key': '3_1532075528928337920'}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 23, 'username': 'gabrielboric', 'id': '73981088'}]}, 'created_at': '2022-06-01T19:04:06.000Z', 'id': '1532075533231476736', 'public_metrics': {'retweet_count': 2, 'reply_count': 0, 'like_count': 2, 'quote_count': 0}, 'text': '@Fenpruss @gabrielboric Ya está garantizada en la Constitución actual y de hecho hay patologías que tienen especial atención. La NC no lo garantiza. https://t.co/nV54PaB61E', 'url': 'https://t.co/nV54PaB61E'}\n",
      "{'entities': {'hashtags': [{'start': 106, 'end': 121, 'tag': 'mentirapublica'}, {'start': 122, 'end': 138, 'tag': 'cuentapublica22'}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 26, 'username': 'ISPinteramerica', 'id': '3414180784'}]}, 'created_at': '2022-06-01T15:06:20.000Z', 'id': '1532015698670665729', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'text': '@Fenpruss @ISPinteramerica por qué la Fenpruss en sus calendarios tiene fotos de la linconao y la loncón? #mentirapublica #cuentapublica22', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 19, 'username': 'Cutchile', 'id': '289376883'}, {'start': 20, 'end': 30, 'username': 'salud_cut', 'id': '1166359400988270593'}, {'start': 31, 'end': 45, 'username': 'ConfusamChile', 'id': '203352616'}, {'start': 46, 'end': 61, 'username': 'saludunderecho', 'id': '1213950711257423872'}, {'start': 62, 'end': 75, 'username': 'CNT_NOmasAFP', 'id': '1564096190'}, {'start': 76, 'end': 91, 'username': 'AuroraDelgadoV', 'id': '1106224517649784832'}, {'start': 92, 'end': 104, 'username': 'medicanatyh', 'id': '385076006'}, {'start': 105, 'end': 114, 'username': 'MEQChile', 'id': '433450406'}, {'start': 115, 'end': 127, 'username': 'gdominguez_', 'id': '772898546328694784'}, {'start': 128, 'end': 140, 'username': 'ElisaLoncon', 'id': '376516710'}]}, 'created_at': '2022-05-28T15:16:19.000Z', 'id': '1530568658669412354', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'text': '@Fenpruss @Cutchile @salud_cut @ConfusamChile @saludunderecho @CNT_NOmasAFP @AuroraDelgadoV @medicanatyh @MEQChile @gdominguez_ @ElisaLoncon La unica salida es  rechasar....por que la federacion hace campaña politica en vez de preocuparse de los problemas de sus asociados....', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'annotations': [{'start': 10, 'end': 20, 'probability': 0.9044, 'type': 'Place', 'normalized_text': 'Antofagasta'}], 'urls': [{'start': 186, 'end': 209, 'url': 'https://t.co/DwVIxnuuBr', 'expanded_url': 'https://www.instagram.com/p/Cd1PAH1Fagg/?igshid=YTgzYjQ4ZTY=', 'display_url': 'instagram.com/p/Cd1PAH1Fagg/…', 'status': 200, 'title': 'Fenpruss Antofagasta (@fenprussantofagasta) • Instagram photo', 'description': '0 Likes, 0 Comments - Fenpruss Antofagasta (@fenprussantofagasta) on Instagram: “@Fenpruss Antofagasta, adhiere al saludo de nuestro directorio nacional, en el día del profesional…”', 'unwound_url': 'https://www.instagram.com/p/Cd1PAH1Fagg/?igshid=YTgzYjQ4ZTY='}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}]}, 'created_at': '2022-05-21T19:26:48.000Z', 'id': '1528094978823667712', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 2, 'quote_count': 0}, 'text': '@Fenpruss Antofagasta, adhiere al saludo de nuestro directorio nacional, en el día del profesional abogada y abogado. Reconocemos ampliamente la labor que cumplen en el equipo de salud. https://t.co/DwVIxnuuBr', 'url': 'https://t.co/DwVIxnuuBr'}\n",
      "{'entities': {'urls': [{'start': 10, 'end': 33, 'url': 'https://t.co/RJvNA6rPDO', 'expanded_url': 'https://twitter.com/HCMagallanes/status/1527692963282681856', 'display_url': 'twitter.com/HCMagallanes/s…'}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}]}, 'created_at': '2022-05-20T20:02:00.000Z', 'id': '1527741449348915200', 'public_metrics': {'retweet_count': 2, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}, 'text': '@Fenpruss https://t.co/RJvNA6rPDO', 'url': 'https://t.co/RJvNA6rPDO'}\n",
      "{'entities': {'urls': [{'start': 59, 'end': 82, 'url': 'https://t.co/0r5DrrxJou', 'expanded_url': 'https://twitter.com/Fenpruss/status/1526953784336867328', 'display_url': 'twitter.com/Fenpruss/statu…'}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 47, 'end': 58, 'username': 'SelmaNuez1', 'id': '865985809354248192'}]}, 'created_at': '2022-05-18T16:04:52.000Z', 'id': '1526956999224659968', 'public_metrics': {'retweet_count': 2, 'reply_count': 0, 'like_count': 7, 'quote_count': 0}, 'text': '@Fenpruss presente con el Cuidado Infantil con @SelmaNuez1 https://t.co/0r5DrrxJou', 'url': 'https://t.co/0r5DrrxJou'}\n",
      "{'entities': {'hashtags': [{'start': 37, 'end': 62, 'tag': 'MenosAplausosMasDerechos'}, {'start': 63, 'end': 68, 'tag': 'YaNo'}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}]}, 'created_at': '2022-05-17T15:03:38.000Z', 'id': '1526579200374603779', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}, 'text': '@Fenpruss Excelente colegas 👍 👏 👌 😉  #MenosAplausosMasDerechos #YaNo EstasSolo', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 26, 'username': 'ministeriosalud', 'id': '153825949'}, {'start': 27, 'end': 37, 'username': 'begoyarza', 'id': '540097287'}]}, 'created_at': '2022-05-14T00:50:26.000Z', 'id': '1525277320084439040', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}, 'text': '@Fenpruss @ministeriosalud @begoyarza Cariños, tan importante trabajo del directorio, los felicito', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 20, 'username': 'begoyarza', 'id': '540097287'}, {'start': 21, 'end': 37, 'username': 'ministeriosalud', 'id': '153825949'}, {'start': 38, 'end': 48, 'username': 'salud_cut', 'id': '1166359400988270593'}]}, 'created_at': '2022-05-13T19:03:15.000Z', 'id': '1525189950072934400', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'text': '@Fenpruss @begoyarza @ministeriosalud @salud_cut 💪💪👏👏👏🙌💙💙', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 20, 'username': 'begoyarza', 'id': '540097287'}, {'start': 21, 'end': 37, 'username': 'ministeriosalud', 'id': '153825949'}, {'start': 38, 'end': 48, 'username': 'salud_cut', 'id': '1166359400988270593'}]}, 'created_at': '2022-05-13T17:08:55.000Z', 'id': '1525161176526598144', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'text': '@Fenpruss @begoyarza @ministeriosalud @salud_cut Carrera Funcionaria!!! 💙🙏', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'annotations': [{'start': 56, 'end': 71, 'probability': 0.5361, 'type': 'Person', 'normalized_text': 'Profesor Assenie'}, {'start': 75, 'end': 83, 'probability': 0.6019, 'type': 'Person', 'normalized_text': 'Rosinelli'}], 'hashtags': [{'start': 141, 'end': 166, 'tag': 'MenosAplausosMasDerechod'}], 'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 20, 'username': 'begoyarza', 'id': '540097287'}, {'start': 21, 'end': 37, 'username': 'ministeriosalud', 'id': '153825949'}, {'start': 38, 'end': 48, 'username': 'salud_cut', 'id': '1166359400988270593'}]}, 'created_at': '2022-05-13T17:06:53.000Z', 'id': '1525160667887435777', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'text': '@Fenpruss @begoyarza @ministeriosalud @salud_cut Veo al Profesor Assenie y Rosinelli que eminencias!!!!!! Gracias Colegas por representarnos #MenosAplausosMasDerechod', 'url': \"Error: 'urls'\"}\n",
      "{'entities': {'mentions': [{'start': 0, 'end': 9, 'username': 'Fenpruss', 'id': '75044282'}, {'start': 10, 'end': 19, 'username': 'MEQChile', 'id': '433450406'}, {'start': 20, 'end': 29, 'username': 'Cutchile', 'id': '289376883'}, {'start': 30, 'end': 40, 'username': 'salud_cut', 'id': '1166359400988270593'}, {'start': 41, 'end': 56, 'username': 'AuroraDelgadoV', 'id': '1106224517649784832'}, {'start': 57, 'end': 69, 'username': 'cesarvalenz', 'id': '160246897'}, {'start': 70, 'end': 82, 'username': 'gdominguez_', 'id': '772898546328694784'}, {'start': 83, 'end': 98, 'username': 'saludunderecho', 'id': '1213950711257423872'}, {'start': 99, 'end': 113, 'username': 'ConfusamChile', 'id': '203352616'}, {'start': 114, 'end': 128, 'username': 'ValeMirandaCC', 'id': '78153321'}]}, 'created_at': '2022-05-09T19:50:20.000Z', 'id': '1523752248861372416', 'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'text': '@Fenpruss @MEQChile @Cutchile @salud_cut @AuroraDelgadoV @cesarvalenz @gdominguez_ @saludunderecho @ConfusamChile @ValeMirandaCC piensan que quitar la libre elección en salud o sistema previsional, los recursos van a ir de un sistema a otro ?\\n los que cotizan en salud hacen el \"esfuerzo\" por obtener un mejor servicio de salud al igual que los que cotizan en afp ,buscan tener una mejor jubilación.', 'url': \"Error: 'urls'\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\nicol\\\\Proyectos\\\\GitHub\\\\Consultorías\\\\Twitter\\\\trade_union_tweets\\\\storage\\\\20220601_1934_trade_union_tweets.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d0b03959b570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mpath_children\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'storage'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{date_id}_{time_id}_trade_union_tweets.xlsx\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_children\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_dfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Sheet1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Generating concatenated DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicol\\Proyectos\\GitHub\\Consultorías\\Twitter\\trade_union_tweets\\utils\\functions.py\u001b[0m in \u001b[0;36mwrite_excel\u001b[1;34m(filepath, sheetname, dataframe, errase)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# Storing the DataFrame in a specific sheet of the Excel Book\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     with pd.ExcelWriter(filepath, engine='openpyxl', mode='a',\n\u001b[0m\u001b[0;32m     62\u001b[0m                         if_sheet_exists=\"replace\") as writer:\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\Twitter-API\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\Twitter-API\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIOHandles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"copression\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m    926\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\nicol\\anaconda3\\envs\\Twitter-API\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\nicol\\\\Proyectos\\\\GitHub\\\\Consultorías\\\\Twitter\\\\trade_union_tweets\\\\storage\\\\20220601_1934_trade_union_tweets.xlsx'"
     ]
    }
   ],
   "source": [
    "importlib.reload(functions)\n",
    "list_dfs = []\n",
    "\n",
    "aux = 1\n",
    "\n",
    "# Generating list of data and storage\n",
    "for account in tqdm(dict_accounts.keys()):\n",
    "    raw_list = [elem['data'] for elem in tweets_by_account[account]]\n",
    "    flat_list = [item for sublist in raw_list for item in sublist]\n",
    "    \n",
    "    if len(flat_list) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Enritching\n",
    "    list_local = []\n",
    "    \n",
    "    for elem in flat_list:\n",
    "        print(elem)\n",
    "        aux += 1\n",
    "\n",
    "        if aux > 12:\n",
    "            break\n",
    "        \n",
    "        try: # Sometimes there is no url to be found\n",
    "            elem['url'] = elem['entities']['urls'][0]['url']\n",
    "        except Exception as e:\n",
    "            elem['url'] = f\"Error: {e}\"\n",
    "            \n",
    "        dict_local = {**elem, **elem['public_metrics']}\n",
    "        list_local.append(dict_local)\n",
    "        \n",
    "    df_local = pd.DataFrame(list_local)\n",
    "    df_local['by'] = account\n",
    "    \n",
    "    # Fixing date columns\n",
    "    df_local['created_at'] = pd.to_datetime(df_local['created_at'],\n",
    "                                            infer_datetime_format=True)\n",
    "    \n",
    "    df_local['created_at'] = df_local['created_at'].dt.strftime('%F %T')\n",
    "    \n",
    "    # Selecting columns to maintain\n",
    "    list_dfs.append(df_local[['created_at', 'by', 'text','retweet_count',\n",
    "                              'reply_count', 'like_count', 'quote_count', 'url']])\n",
    "    \n",
    "    # Writing our df to an Excel file\n",
    "    path_children = ['storage', f\"{date_id}_{time_id}_trade_union_tweets.xlsx\"]\n",
    "    filepath = str(functions.script_path(path_children))\n",
    "    functions.write_excel(filepath, account, list_dfs[-1], errase='Sheet1')\n",
    "\n",
    "# Generating concatenated DataFrame\n",
    "df = pd.concat(list_dfs, ignore_index=True)\n",
    "print('Tabla correctamente descargada y disponible para su análisis...')\n",
    "display(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa57e2c-54ef-4792-901d-35b736ad5fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79b08912f02a875a930b408f839099c25315e7b2d729987a0559484b4b0e021d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('Twitter-API')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
